{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Consulting Project\n",
    "\n",
    "## (Henri's Solution + Additional Comments)\n",
    "\n",
    "You have been contacted by a top marketing agency to help them out with customer churn (the annual percentage rate at which customers stop subscribing to a service or employees leave a job).\n",
    "\n",
    "A marketing agency has many customers that use their service to produce ads for the client/customer websites.\n",
    "\n",
    "They've noticed that they have quite a bit of churn in clients.\n",
    "\n",
    "They currently randomly assign account managers, but want you to create a machine learning model that will help predict which cutomers will churn (stop buying their service) so that they can correctly assign the customers most at risk to churn an account manager.\n",
    "\n",
    "Luckily they have some historical data, can you help them out?\n",
    "\n",
    "Create a classification algorithm that will help classify whether or not a customer churned.\n",
    "\n",
    "Then the company can test this against incoming data for future customers to predict which customers will churn and assign them an account manager.\n",
    "\n",
    "The data is under ```customer_churn.csv```.  Let's quickly go over the data and what your main task is.\n",
    "\n",
    "- ```Name```: Name of the latest contact at Company.\n",
    "- ```Age```: Customer Age\n",
    "- ```Total_Purchase```: Total Ads Purchased\n",
    "- ```Account_Manager```: Binary 0 -> No manager, 1 -> Account manager assigned\n",
    "- ```Years```: Total Years as a customer\n",
    "- ```Num_sites```: Number of websites that use the service\n",
    "- ```Onboard_date```: Date that the name of the latest contact was onboarded\n",
    "- ```Location```: Client HQ Address\n",
    "- ```Company```: Name of the Client Company\n",
    "- ```Churn```: 0 or 1 indicating whether customer has churned.\n",
    "\n",
    "Your goal is to create a model that can predict whether a customer will churn (0 or 1) based off the features.\n",
    "\n",
    "Remember that the account manager is curreently randomly assigned.\n",
    "\n",
    "As always, treat this consulting project as a loosely guided exercise, or skip ahead and treat it as a code along project.\n",
    "\n",
    "Best of luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a spark session\n",
    "spark = SparkSession.builder.appName(\"churn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our data.\n",
    "data = spark.read.csv(\"customer_churn.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "Number of samples is: 900.\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "print(\"\\n\")\n",
    "print(\"Number of samples is: {:.0f}.\".format(data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Names='Cameron Williams', Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Years=7.22, Num_Sites=8.0, Onboard_date=datetime.datetime(2013, 8, 30, 7, 0, 40), Location='10265 Elizabeth Mission Barkerburgh, AK 89518', Company='Harvey LLC', Churn=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA\n",
    "data.head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Names='Cameron Williams', Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Years=7.22, Num_Sites=8.0, Onboard_date=datetime.datetime(2013, 8, 30, 7, 0, 40), Location='10265 Elizabeth Mission Barkerburgh, AK 89518', Company='Harvey LLC', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Kevin Mueller', Age=41.0, Total_Purchase=11916.22, Account_Manager=0, Years=6.5, Num_Sites=11.0, Onboard_date=datetime.datetime(2013, 8, 13, 0, 38, 46), Location='6157 Frank Gardens Suite 019 Carloshaven, RI 17756', Company='Wilson PLC', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Eric Lozano', Age=38.0, Total_Purchase=12884.75, Account_Manager=0, Years=6.67, Num_Sites=12.0, Onboard_date=datetime.datetime(2016, 6, 29, 6, 20, 7), Location='1331 Keith Court Alyssahaven, DE 90114', Company='Miller, Johnson and Wallace', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Phillip White', Age=42.0, Total_Purchase=8010.76, Account_Manager=0, Years=6.71, Num_Sites=10.0, Onboard_date=datetime.datetime(2014, 4, 22, 12, 43, 12), Location='13120 Daniel Mount Angelabury, WY 30645-4695', Company='Smith Inc', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Cynthia Norton', Age=37.0, Total_Purchase=9191.58, Account_Manager=0, Years=5.56, Num_Sites=9.0, Onboard_date=datetime.datetime(2016, 1, 19, 15, 31, 15), Location='765 Tricia Row Karenshire, MH 71730', Company='Love-Jones', Churn=1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "for row in data.head(5):\n",
    "    print(row)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cols = data.select([\"Age\", \"Total_Purchase\", \"Years\", \"Num_Sites\", \"Churn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following, we create an assembler.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your assembler object.\n",
    "assembler = VectorAssembler(inputCols=[\"Age\", \"Total_Purchase\", \"Years\", \"Num_Sites\"],\n",
    "                            outputCol=\"features\")\n",
    "# Concerning inputCols:\n",
    "# --- \"Names\": is too arbitrary; won't help in our model.\n",
    "# --- \"Account_Manager\": we don't expect this to help much since they are randomly assigned.\n",
    "#     But yet the instructor includes it in his assembler...  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the output.\n",
    "# Notice that we only select \"features\" and \"Churn\".\n",
    "proc_data = assembler.transform(dataset=desired_cols).select([\"features\", \"Churn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=DenseVector([42.0, 11066.8, 7.22, 8.0]), Churn=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic EDA.\n",
    "proc_data.head(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate and train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a LogisticRegression model.\n",
    "log_reg = LogisticRegression(labelCol=\"Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data.\n",
    "train_data, test_data = proc_data.randomSplit([0.7, 0.3], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data.\n",
    "fitted_log_reg = log_reg.fit(dataset=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out a summary of the trained model.\n",
    "training_summary = fitted_log_reg.summary\n",
    "# training_summary --> <pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary at 0x7f76ed11a860>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              Churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                633|                633|\n",
      "|   mean|0.15639810426540285|0.11216429699842022|\n",
      "| stddev| 0.3635195998705865|0.31581804295341376|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_summary.predictions.describe().show()\n",
    "# A good comparison to make is between \"Churn\" and \"prediction\" \"mean\" and \"stddev\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the results.**\n",
    "\n",
    "You will see below that we finally calculate the ```auroc``` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates the model on a test dataset\n",
    "preds_and_labels = fitted_log_reg.evaluate(dataset=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|Churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[25.0,9672.03,5.4...|    0|[4.45728553683191...|[0.98853908393873...|       0.0|\n",
      "|[26.0,8787.39,5.4...|    1|[1.07747513654642...|[0.74601587906872...|       0.0|\n",
      "|[26.0,8939.61,4.5...|    0|[6.08134633024471...|[0.99772011168408...|       0.0|\n",
      "|[28.0,11204.23,3....|    0|[1.69011971259467...|[0.84423990259824...|       0.0|\n",
      "|[29.0,5900.78,5.5...|    0|[4.44595421204329...|[0.98840999172866...|       0.0|\n",
      "|[29.0,11274.46,4....|    0|[4.64709674466339...|[0.99050168115979...|       0.0|\n",
      "|[29.0,12711.15,5....|    0|[5.00285442680424...|[0.99332609877076...|       0.0|\n",
      "|[29.0,13240.01,4....|    0|[6.70687780527334...|[0.99877901764305...|       0.0|\n",
      "|[30.0,10183.98,5....|    0|[3.15571935401620...|[0.95913348972409...|       0.0|\n",
      "|[30.0,11575.37,5....|    1|[4.15367223849468...|[0.98453625145497...|       0.0|\n",
      "|[30.0,13473.35,3....|    0|[2.45541553348186...|[0.92095657741433...|       0.0|\n",
      "|[31.0,7073.61,5.7...|    0|[3.01113254349380...|[0.95307453159379...|       0.0|\n",
      "|[31.0,9574.89,7.3...|    0|[3.13460844759932...|[0.95829794974921...|       0.0|\n",
      "|[31.0,11297.57,6....|    1|[1.30868337489026...|[0.78729275345341...|       0.0|\n",
      "|[31.0,12264.68,5....|    0|[3.69988944240257...|[0.97587037537688...|       0.0|\n",
      "|[32.0,6367.22,2.8...|    0|[3.36225134811519...|[0.96650373904978...|       0.0|\n",
      "|[32.0,8575.71,4.2...|    0|[3.60544926643754...|[0.97354372236313...|       0.0|\n",
      "|[32.0,9036.27,7.1...|    0|[-0.2025171758901...|[0.44954303841243...|       1.0|\n",
      "|[32.0,9472.72,1.0...|    0|[4.09507943233639...|[0.98361840272523...|       0.0|\n",
      "|[32.0,9885.12,6.9...|    1|[2.12964996484939...|[0.89375177372866...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grab the \"predictions\" DataFrame off `preds_and_labels`.\n",
    "preds_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the AUC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_evaluator = BinaryClassificationEvaluator(labelCol=\"Churn\",\n",
    "                                             rawPredictionCol=\"probability\")\n",
    "# Henri's question is:  \"Why does the instructor in his solution set rawPredictionCol to 'prediction'?!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9139433551198269\n"
     ]
    }
   ],
   "source": [
    "# Evaluates the output.\n",
    "auroc = my_evaluator.evaluate(dataset=preds_and_labels.predictions)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Brand New Data that do _NOT_ have any labels\n",
    "\n",
    "The file of interest here is  \n",
    "```new_customers.csv```\n",
    "\n",
    "The following mimics **deployment** in real-life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the logistic regression model on the ENTIRE dataset.\n",
    "# (At least this is what the instructor is doing.)\n",
    "final_log_reg = log_reg.fit(dataset=proc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = spark.read.csv(\"new_customers.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "Row(Names='Andrew Mccall', Age=37.0, Total_Purchase=9935.53, Account_Manager=1, Years=7.71, Num_Sites=8.0, Onboard_date=datetime.datetime(2011, 8, 29, 18, 37, 54), Location='38612 Johnny Stravenue Nataliebury, WI 15717-8316', Company='King Ltd')\n",
      "\n",
      "\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "unseen.printSchema()\n",
    "print(\"\\n\")\n",
    "\n",
    "print(unseen.head(1)[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(unseen.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to transform the \"unseen\" DataFrame.\n",
    "unseen_processed = assembler.transform(dataset=unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm that we now have an additional \"features\" column:\n",
    "unseen_processed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the DataFrame.\n",
    "unseen_transformed = final_log_reg.transform(dataset=unseen_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|         Company|prediction|\n",
      "+----------------+----------+\n",
      "|        King Ltd|       0.0|\n",
      "|   Cannon-Benson|       1.0|\n",
      "|Barron-Robertson|       1.0|\n",
      "|   Sexton-Golden|       1.0|\n",
      "|        Wood LLC|       0.0|\n",
      "|   Parks-Robbins|       1.0|\n",
      "+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What we mostly care about, amidst the other columns in the DataFrame, is the \"prediction\" column.\n",
    "unseen_transformed.select([\"Company\", \"prediction\"]).show()\n",
    "# Notice that our \"unseen\" DataFrame is very small; only work with 6 customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Therefore, we need to assign account managers to:***\n",
    "- ```Cannon-Benson```\n",
    "- ```Barron-Robertson```\n",
    "- ```Sexton-Golden```\n",
    "- ```Parks-Robbins```\n",
    "\n",
    "Customers that are **not likely** to churn include:\n",
    "- ```King Ltd```\n",
    "- ```Wood LLC```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
