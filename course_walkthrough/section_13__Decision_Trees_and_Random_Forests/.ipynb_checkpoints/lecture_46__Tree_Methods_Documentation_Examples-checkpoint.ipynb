{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods Documentation Examples.\n",
    "\n",
    "We'll work through the concepts:\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient Boosted Trees.\n",
    "\n",
    "We will also expand a little more from the documentation example and show some useful evaluation features.\n",
    "Also expand on how you can use multi-class evaluators for binary-classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new Spark Session:\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"trees\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# A simple pipeline, which acts as an estimator.  A Pipeline consists of a sequence of stages, each of which is\n",
    "# either an Estimator or a Transformer.\n",
    "# When Pipeline.fit() is called, the stages are executed in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (RandomForestClassifier, \n",
    "                                       GBTClassifier,\n",
    "                                       DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor, GBTRegressor\n",
    "# Notice how you can can make use of tree methods for regression problems as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split this into a training set and into a test set:\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start of by creating the most basic model: the DecisionTreeClassifier\n",
    "dec_tree_cls = DecisionTreeClassifier()  # The defaults already match\n",
    "\n",
    "# Other parameters you can play around with include:\n",
    "# --- maxDepth\n",
    "# --- maxBins\n",
    "# --- minInfoGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a RandomForestClassifier\n",
    "rnd_forest_cls = RandomForestClassifier(numTrees=100)\n",
    "\n",
    "# An important parameter to play around with is:\n",
    "# --- numTrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Gradient-Boosted Classifier\n",
    "grad_boosted_cls = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifiers:\n",
    "fitted_dtc = dec_tree_cls.fit(train_data)\n",
    "fitted_rfc = rnd_forest_cls.fit(train_data)\n",
    "fitted_gbt = grad_boosted_cls.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted models to transform the test data.\n",
    "dtc_preds = fitted_dtc.transform(dataset=test_data)\n",
    "rfc_preds = fitted_rfc.transform(dataset=test_data)\n",
    "gbt_preds = fitted_gbt.transform(dataset=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|    [0.0,1.0]|  [0.0,1.0]|       1.0|\n",
      "|  0.0|(692,[100,101,102...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[121,122,123...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[123,124,125...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[125,126,127...|   [0.0,38.0]|  [0.0,1.0]|       1.0|\n",
      "|  0.0|(692,[126,127,128...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[128,129,130...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[150,151,152...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|   [0.0,38.0]|  [0.0,1.0]|       1.0|\n",
      "|  0.0|(692,[155,156,180...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[234,235,237...|   [27.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[100,101,102...|   [0.0,38.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,38.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,38.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,38.0]|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|   [99.0,1.0]|[0.99,0.01]|       0.0|\n",
      "|  0.0|(692,[100,101,102...|  [58.0,42.0]|[0.58,0.42]|       0.0|\n",
      "|  0.0|(692,[121,122,123...|   [99.0,1.0]|[0.99,0.01]|       0.0|\n",
      "|  0.0|(692,[123,124,125...|   [99.0,1.0]|[0.99,0.01]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [99.0,1.0]|[0.99,0.01]|       0.0|\n",
      "|  0.0|(692,[125,126,127...|  [89.0,11.0]|[0.89,0.11]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [95.0,5.0]|[0.95,0.05]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [94.0,6.0]|[0.94,0.06]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|  [100.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[128,129,130...|   [98.0,2.0]|[0.98,0.02]|       0.0|\n",
      "|  0.0|(692,[150,151,152...|  [74.0,26.0]|[0.74,0.26]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [92.0,8.0]|[0.92,0.08]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|   [91.0,9.0]|[0.91,0.09]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|  [65.0,35.0]|[0.65,0.35]|       0.0|\n",
      "|  0.0|(692,[155,156,180...|   [99.0,1.0]|[0.99,0.01]|       0.0|\n",
      "|  0.0|(692,[234,235,237...|  [77.0,23.0]|[0.77,0.23]|       0.0|\n",
      "|  1.0|(692,[100,101,102...|   [1.0,99.0]|[0.01,0.99]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [2.0,98.0]|[0.02,0.98]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [2.0,98.0]|[0.02,0.98]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [1.0,99.0]|[0.01,0.99]|       1.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[-0.6060962844427...|[0.22931333108869...|       1.0|\n",
      "|  0.0|(692,[100,101,102...|[1.30134115583878...|[0.93103400929289...|       0.0|\n",
      "|  0.0|(692,[121,122,123...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[-1.0207775731910...|[0.11490847189109...|       1.0|\n",
      "|  0.0|(692,[126,127,128...|[1.32965041179661...|[0.93458193293355...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[-1.0207775731910...|[0.11490847189109...|       1.0|\n",
      "|  0.0|(692,[155,156,180...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[234,235,237...|[1.23927370673482...|[0.92262416306908...|       0.0|\n",
      "|  1.0|(692,[100,101,102...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the predictions:\n",
    "dtc_preds.show()\n",
    "rfc_preds.show()\n",
    "gbt_preds.show()\n",
    "# gbt_preds DOES HAVE \"rawPrediction\" and \"probability\" columns.  Instructor is using old PySpark version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an evaluator on the predictions.\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# We get access to a lot more metrics using the MulticlassClassificationEvaluator such as:\n",
    "# --- precision\n",
    "# --- recall\n",
    "# --- accuracy\n",
    "# --- auroc\n",
    "# --- etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "# metric name can be either one of the following:\n",
    "# --- f1\n",
    "# --- weightedPrecision\n",
    "# --- weightedRecall\n",
    "# --- accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8823529411764706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Decision Tree Accuracy:\")\n",
    "accuracy_eval.evaluate(dataset=dtc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Random Forest Classifier Accuracy:\")\n",
    "accuracy_eval.evaluate(dataset=rfc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Classifier Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8823529411764706"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"GBT Classifier Accuracy:\")\n",
    "accuracy_eval.evaluate(dataset=gbt_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how we can grab feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {155: 0.0007, 156: 0.0012, 176: 0.0012, 182: 0.0007, 207: 0.0103, 208: 0.0074, 234: 0.0008, 239: 0.0012, 240: 0.0004, 241: 0.0005, 242: 0.0005, 243: 0.0015, 244: 0.0204, 245: 0.0051, 258: 0.0012, 260: 0.0032, 262: 0.0088, 266: 0.0003, 267: 0.0002, 271: 0.0019, 272: 0.0237, 273: 0.0066, 274: 0.0047, 290: 0.0006, 291: 0.0129, 293: 0.0005, 295: 0.0009, 299: 0.0061, 300: 0.0092, 302: 0.0175, 313: 0.0003, 318: 0.0057, 320: 0.0008, 323: 0.0134, 327: 0.0019, 330: 0.0093, 343: 0.0004, 345: 0.0113, 346: 0.0078, 347: 0.0021, 350: 0.0077, 351: 0.0006, 352: 0.0025, 355: 0.0011, 356: 0.0053, 357: 0.0116, 358: 0.0138, 372: 0.0178, 373: 0.0075, 377: 0.0272, 378: 0.0106, 380: 0.0011, 382: 0.0016, 384: 0.0014, 385: 0.0249, 386: 0.0151, 388: 0.002, 398: 0.0012, 399: 0.0143, 401: 0.0061, 405: 0.0513, 406: 0.01, 407: 0.011, 408: 0.0014, 412: 0.0093, 413: 0.0108, 414: 0.0059, 427: 0.0077, 429: 0.0007, 433: 0.0318, 434: 0.0297, 435: 0.0083, 436: 0.0006, 437: 0.0013, 441: 0.0259, 442: 0.0028, 453: 0.0029, 454: 0.01, 455: 0.0477, 456: 0.0182, 460: 0.012, 461: 0.0126, 462: 0.0217, 463: 0.0083, 465: 0.0014, 468: 0.0082, 469: 0.0079, 482: 0.0107, 483: 0.0301, 484: 0.0077, 490: 0.0163, 496: 0.0192, 497: 0.0007, 511: 0.0145, 512: 0.0086, 513: 0.0068, 517: 0.039, 518: 0.0172, 528: 0.0005, 537: 0.0007, 538: 0.0018, 539: 0.0356, 540: 0.0091, 548: 0.0006, 549: 0.0006, 550: 0.005, 556: 0.0021, 566: 0.0014, 567: 0.0014, 568: 0.0041, 578: 0.0082, 579: 0.006, 596: 0.0006, 597: 0.0083, 599: 0.0006, 603: 0.0003, 604: 0.0006, 625: 0.0003, 626: 0.0012, 627: 0.0006, 628: 0.0014, 632: 0.0004, 655: 0.0014, 690: 0.0007})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_rfc.featureImportances\n",
    "# Estimate of the importance of each feature.\n",
    "\n",
    "# From the documentation:\n",
    "# Feature importance for single decision trees can have high variance due to correlated predictor variables.\n",
    "# Consider using a RandomForestClassifier to determine feature importance isntead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
