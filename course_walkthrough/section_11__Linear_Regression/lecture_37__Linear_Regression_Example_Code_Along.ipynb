{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Example Code Along\n",
    "\n",
    "In the resources download, the relevant notebook is called:\n",
    "- ```linear_regression_code_along.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"lr_example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"Ecommerce_Customers.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avatar: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "\n",
    "# The actual value that we are trying to predict is: `Yearly Amount Spent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mstephenson@fernandez.com\n",
      "835 Frank TunnelWrightmouth, MI 82180-9605\n",
      "Violet\n",
      "34.49726772511229\n",
      "12.65565114916675\n",
      "39.57766801952616\n",
      "4.0826206329529615\n",
      "587.9510539684005\n"
     ]
    }
   ],
   "source": [
    "for element in data.head(1)[0]:\n",
    "    print(element)\n",
    "\n",
    "# Inspection of the elements reveal that `Avatar` is just a color.\n",
    "\n",
    "# For this project, we just care about the numerical data:\n",
    "# --- Avg Session Length\n",
    "# --- Time on App\n",
    "# --- Time on Website\n",
    "# --- Length of Membership\n",
    "\n",
    "# And we care about predicting:\n",
    "# --- Yearly Amount Spent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we need to setup the DataFrame for Machine Learning.  This is really an important component of using PySpark MLlib.  We must concentrate on fully grasping what is happening in the following code...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we need to import the vector assembler and vectors.\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Email',\n",
       " 'Address',\n",
       " 'Avatar',\n",
       " 'Avg Session Length',\n",
       " 'Time on App',\n",
       " 'Time on Website',\n",
       " 'Length of Membership',\n",
       " 'Yearly Amount Spent']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed by creating an assembler object.\n",
    "assembler = VectorAssembler(inputCols=['Avg Session Length',\n",
    "                                       'Time on App',\n",
    "                                       'Time on Website',\n",
    "                                       'Length of Membership'],\n",
    "                           outputCol=\"features\")  \n",
    "# VectorAssembler is a feature transformer that merges multiple columns into a vector column.\n",
    "# inputCols is a list of strings of the actual columns that you want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avatar: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Secondly, we want to transform the data.\n",
    "output = assembler.transform(data)  # Notice that we are passing in ALL the data (not just a train/test split).\n",
    "output.printSchema()  # You have everything that you used to have, plus an additional feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([34.4973, 12.6557, 39.5777, 4.0826])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(1)[0][-1]  # Notice that we have here a DenseVector:\n",
    "# DenseVector([34.4973, 12.6557, 39.5777, 4.0826])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            features|Yearly Amount Spent|\n",
      "+--------------------+-------------------+\n",
      "|[34.4972677251122...|  587.9510539684005|\n",
      "|[31.9262720263601...|  392.2049334443264|\n",
      "|[33.0009147556426...| 487.54750486747207|\n",
      "|[34.3055566297555...|  581.8523440352177|\n",
      "|[33.3306725236463...|  599.4060920457634|\n",
      "|[33.8710378793419...|   637.102447915074|\n",
      "|[32.0215955013870...|  521.5721747578274|\n",
      "|[32.7391429383803...|  549.9041461052942|\n",
      "|[33.9877728956856...|  570.2004089636196|\n",
      "|[31.9365486184489...|  427.1993848953282|\n",
      "|[33.9925727749537...|  492.6060127179966|\n",
      "|[33.8793608248049...|  522.3374046069357|\n",
      "|[29.5324289670579...|  408.6403510726275|\n",
      "|[33.1903340437226...|  573.4158673313865|\n",
      "|[32.3879758531538...|  470.4527333009554|\n",
      "|[30.7377203726281...|  461.7807421962299|\n",
      "|[32.1253868972878...| 457.84769594494855|\n",
      "|[32.3388993230671...| 407.70454754954415|\n",
      "|[32.1878120459321...|  452.3156754800354|\n",
      "|[32.6178560628234...|   605.061038804892|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, we create our final_data:\n",
    "final_data = output.select([\"features\", \"Yearly Amount Spent\"])\n",
    "final_data.show()\n",
    "\n",
    "# Notice how now we have a DataFrame whose columns are in the form:  | `features` | `labels` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we need to split up the final_data into a train/test split:\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])  # 70%/30% is a good default choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|Yearly Amount Spent|\n",
      "+-------+-------------------+\n",
      "|  count|                358|\n",
      "|   mean|  498.4636864063505|\n",
      "| stddev|  80.06444722704694|\n",
      "|    min| 256.67058229005585|\n",
      "|    max|  765.5184619388373|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|Yearly Amount Spent|\n",
      "+-------+-------------------+\n",
      "|  count|                142|\n",
      "|   mean| 501.45788306916813|\n",
      "| stddev|  77.63034026924589|\n",
      "|    min|  304.1355915788555|\n",
      "|    max|  744.2218671047146|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we create our Linear Regression Model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol=\"Yearly Amount Spent\")  # We do not adjust the other parameters because they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us see how well our model actually performed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|0.28038733185297815|\n",
      "| 10.709307835746472|\n",
      "| -6.351051578016779|\n",
      "| 2.9216968110291646|\n",
      "| 19.063815641797248|\n",
      "|  3.800463888802483|\n",
      "| -5.315671165363938|\n",
      "|  6.657952018951335|\n",
      "| -7.377146922995848|\n",
      "|  -4.81905280428947|\n",
      "| -9.353148325667178|\n",
      "|   1.07830180297492|\n",
      "|-2.2770975477609454|\n",
      "| -10.39882845281511|\n",
      "| -8.975074456393429|\n",
      "|-17.489441897049858|\n",
      "| 10.812557456158515|\n",
      "|-1.8995175961796917|\n",
      "|  8.113243129177022|\n",
      "|  5.408183605730301|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.357332800814493"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853677738859922"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.r2\n",
    "# 0.98 indicates that our model is explaining a lot of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|Yearly Amount Spent|\n",
      "+-------+-------------------+\n",
      "|  count|                500|\n",
      "|   mean|  499.3140382585909|\n",
      "| stddev|   79.3147815497068|\n",
      "|    min| 256.67058229005585|\n",
      "|    max|  765.5184619388373|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare rootMeanSquaredError with the following report:\n",
    "final_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us review how we can deploy this model for data for which we only have feature data (and no label data).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[30.5743636841713...|\n",
      "|[30.7377203726281...|\n",
      "|[31.0613251567161...|\n",
      "|[31.3091926408918...|\n",
      "|[31.3123495994443...|\n",
      "|[31.3584771924370...|\n",
      "|[31.5147378578019...|\n",
      "|[31.6548096756927...|\n",
      "|[31.7207699002873...|\n",
      "|[31.7656188210424...|\n",
      "|[31.8279790554652...|\n",
      "|[31.8293464559211...|\n",
      "|[31.8627411090001...|\n",
      "|[31.8648325480987...|\n",
      "|[31.8854062999117...|\n",
      "|[31.9048571310136...|\n",
      "|[31.9096268275227...|\n",
      "|[31.9120759292006...|\n",
      "|[31.9549038566348...|\n",
      "|[31.9764800614612...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We \"mimic\" the deployment procedure in the following:\n",
    "unlabeled_data = test_data.select(\"features\")\n",
    "unlabeled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[30.5743636841713...| 441.7840264262127|\n",
      "|[30.7377203726281...| 451.0714343604834|\n",
      "|[31.0613251567161...| 493.9065096359184|\n",
      "|[31.3091926408918...|429.79902102890446|\n",
      "|[31.3123495994443...|444.52760238614337|\n",
      "|[31.3584771924370...| 491.3754865606729|\n",
      "|[31.5147378578019...|495.12815916182535|\n",
      "|[31.6548096756927...| 468.6054717085972|\n",
      "|[31.7207699002873...| 546.1520804010188|\n",
      "|[31.7656188210424...| 501.3731344398966|\n",
      "|[31.8279790554652...| 449.3558958726087|\n",
      "|[31.8293464559211...|384.07403618500007|\n",
      "|[31.8627411090001...| 558.5752387218076|\n",
      "|[31.8648325480987...| 450.2901089296288|\n",
      "|[31.8854062999117...|399.07834742886894|\n",
      "|[31.9048571310136...|  491.439299319866|\n",
      "|[31.9096268275227...| 552.6334782170807|\n",
      "|[31.9120759292006...| 389.4342339018874|\n",
      "|[31.9549038566348...|431.88463681074995|\n",
      "|[31.9764800614612...| 325.1862624283699|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coming up next is going to be a consulting project.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
