{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"lrex\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our training data:\n",
    "training = spark.read.format(\"libsvm\").load(\"sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()\n",
    "# This is the actual format that Spark needs to run an actual MachineLearning algorithm on it.\n",
    "# The features column has inside of it some vector; a vector of all the features belonging to that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating an instance of our model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\",\n",
    "                     predictionCol=\"prediction\")\n",
    "# By default, the featuresCol column is called \"features\".\n",
    "# By default, the labelCol column is called \"label\".\n",
    "# By default, the predictionCol column is called \"prediction\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to simply fit (or train) the model.\n",
    "lr_Model = lr.fit(dataset=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0073, 0.8314, -0.8095, 2.4412, 0.5192, 1.1535, -0.2989, -0.5129, -0.6197, 0.6956])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the coefficients of our model.\n",
    "lr_Model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14228558260358093"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the intercept of our model.\n",
    "lr_Model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_summary = lr_Model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027839179518600154\n",
      "10.16309157133015\n"
     ]
    }
   ],
   "source": [
    "print(training_summary.r2)  # How much variance is explained by your model.\n",
    "print(training_summary.rootMeanSquaredError)  # Some error metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually, we've comitted the error of training our model on _all_ of the available data!\n",
    "\n",
    "Let us see in the following, how we can perform a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = spark.read.format(\"libsvm\").load(\"sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[label: double, features: vector],\n",
       " DataFrame[label: double, features: vector]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_object = all_data.randomSplit([0.7, 0.3])\n",
    "# First dataframe out will contain 70% of the data\n",
    "# Second dataframe out will contain 30% of the data\n",
    "\n",
    "split_object  # i.e. what we get back is a list of 2 dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following, we use tuple unpacking, which makes a lot more sense:\n",
    "train_data, test_data = all_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# It is already RANDOMLY SPLIT for you.  It's not like the top 70% is grabbed and then the last 30% at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|                361|\n",
      "|   mean| 0.2800458889274214|\n",
      "| stddev| 10.073894730679347|\n",
      "|    min|-28.571478869743427|\n",
      "|    max| 26.903524792043335|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|                140|\n",
      "|   mean| 0.1971766715492226|\n",
      "| stddev| 10.959265603140585|\n",
      "|    min|-28.046018037776633|\n",
      "|    max|  27.78383192005107|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to evaluate how well my model did.\n",
    "# Not on the training data, but instead on the test data.\n",
    "test_results = correct_model.evaluate(dataset=test_data)\n",
    "# We are comparing the labels in the test_data with the predicted labels made by the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| -27.03755538787312|\n",
      "| -27.25365238524946|\n",
      "| -21.54844689306325|\n",
      "|-19.830761582535636|\n",
      "|-20.016220607064138|\n",
      "| -19.01886284128381|\n",
      "|-15.162437869421884|\n",
      "| -16.85583236685477|\n",
      "|-18.729534334061096|\n",
      "| -16.64722581254161|\n",
      "|-16.984828866170478|\n",
      "|-15.506648073408895|\n",
      "|-11.622945117308959|\n",
      "|-13.428786664602901|\n",
      "|-16.964773941721454|\n",
      "| -8.886664209243794|\n",
      "|-13.805522067728921|\n",
      "|-11.420648238188766|\n",
      "|  -9.02719799547021|\n",
      "|-10.680619015242364|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "10.979761016808233\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()  # show the actual residuals.\n",
    "print(test_results.rootMeanSquaredError)  # Show the error metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are comfortable with your model, your model is ready for deployment.  \n",
    "It makes sense to deploy your model onto data which has no labels.  \n",
    "Let's mimic that in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data = test_data.select(\"features\")\n",
    "unlabeled_data.show()  # Notice that this is only the \"features\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = correct_model.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|          prediction|\n",
      "+--------------------+--------------------+\n",
      "|(10,[0,1,2,3,4,5,...| -1.0084626499035132|\n",
      "|(10,[0,1,2,3,4,5,...|   4.303826449053384|\n",
      "|(10,[0,1,2,3,4,5,...|  0.1160591288974433|\n",
      "|(10,[0,1,2,3,4,5,...|  0.1634429671639186|\n",
      "|(10,[0,1,2,3,4,5,...|  0.6138845768495844|\n",
      "|(10,[0,1,2,3,4,5,...|  0.7436492752791787|\n",
      "|(10,[0,1,2,3,4,5,...|  -2.331762487461459|\n",
      "|(10,[0,1,2,3,4,5,...|-0.47088836582117644|\n",
      "|(10,[0,1,2,3,4,5,...|  1.6641347081850795|\n",
      "|(10,[0,1,2,3,4,5,...|-0.07187102106348087|\n",
      "|(10,[0,1,2,3,4,5,...|  0.8334795148933665|\n",
      "|(10,[0,1,2,3,4,5,...| 0.13079035009659873|\n",
      "|(10,[0,1,2,3,4,5,...| -1.5303904890565716|\n",
      "|(10,[0,1,2,3,4,5,...|  0.3888586004982866|\n",
      "|(10,[0,1,2,3,4,5,...|  4.0425508383510325|\n",
      "|(10,[0,1,2,3,4,5,...|  -3.886562790007404|\n",
      "|(10,[0,1,2,3,4,5,...|  1.3047482823738663|\n",
      "|(10,[0,1,2,3,4,5,...| -1.0586319732627305|\n",
      "|(10,[0,1,2,3,4,5,...|  -3.383748407369951|\n",
      "|(10,[0,1,2,3,4,5,...| -1.4497341970455646|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()  # gives you the predicted value based off the values of the features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
